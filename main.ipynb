{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing pre-trained models"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model # 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np \n",
    "from PIL import Image\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\haris\\miniconda3\\envs\\forPyTorch\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Could not find image processor class in the image processor config or the model config. Loading based on pattern matching with the model's feature extractor configuration.\n",
      "The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "pipe = pipeline(\"object-detection\", model=\"valentinafeve/yolos-fashionpedia\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 0.9643442630767822,\n",
       "  'label': 'sleeve',\n",
       "  'box': {'xmin': 786, 'ymin': 181, 'xmax': 896, 'ymax': 496}},\n",
       " {'score': 0.9950535893440247,\n",
       "  'label': 'sleeve',\n",
       "  'box': {'xmin': 517, 'ymin': 208, 'xmax': 624, 'ymax': 537}}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe(\"temp_frame.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 0.9653264880180359,\n",
       "  'label': 'shoe',\n",
       "  'box': {'xmin': 81, 'ymin': 512, 'xmax': 111, 'ymax': 578}},\n",
       " {'score': 0.9268865585327148,\n",
       "  'label': 'shoe',\n",
       "  'box': {'xmin': 105, 'ymin': 525, 'xmax': 129, 'ymax': 569}},\n",
       " {'score': 0.9727214574813843,\n",
       "  'label': 'sleeve',\n",
       "  'box': {'xmin': 117, 'ymin': 108, 'xmax': 181, 'ymax': 266}},\n",
       " {'score': 0.984233021736145,\n",
       "  'label': 'sleeve',\n",
       "  'box': {'xmin': 14, 'ymin': 123, 'xmax': 86, 'ymax': 238}}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe(\"test.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video OK! No Inappropriate Content Detected\n"
     ]
    }
   ],
   "source": [
    "def classify_image(img_array):\n",
    "    predictions = pipe(img_array)\n",
    "    decoded_predictions =  predictions\n",
    "    return decoded_predictions   \n",
    " \n",
    "\n",
    "def draw_boxes_on_frame(frame, predictions):\n",
    "    for prediction in predictions:\n",
    "        label = prediction['label']\n",
    "        box = prediction['box']\n",
    " \n",
    "        xmin, ymin, xmax, ymax = box['xmin'], box['ymin'], box['xmax'], box['ymax'] \n",
    "        cv2.rectangle(frame, (xmin, ymin), (xmax, ymax), (0, 255, 0), 2) \n",
    "        label_text = f'{label}: {prediction[\"score\"]:.2f}'\n",
    "        cv2.putText(frame, label_text, (xmin, ymin - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "    return frame\n",
    "\n",
    "def classify_video(video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    \n",
    "    frame_interval = 1.5   \n",
    "    last_prediction_time = time.time()\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        current_time = time.time()\n",
    "\n",
    "        if current_time - last_prediction_time >= frame_interval:\n",
    "            pil_image = Image.fromarray(np.uint8(frame)) \n",
    "            predicted_class = classify_image(pil_image)   \n",
    "\n",
    "            print(predicted_class)\n",
    "\n",
    "            frame_with_boxes = draw_boxes_on_frame(frame.copy(), predicted_class)\n",
    "            cv2.imshow('Video with Bounding Boxes', frame_with_boxes)\n",
    " \n",
    "            last_prediction_time = current_time\n",
    "   \n",
    "        if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "            break\n",
    " \n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows() \n",
    "    print(\"Video OK! No Inappropriate Content Detected\")\n",
    "\n",
    "video_path = 'temp_frame.jpg' \n",
    "classify_video(video_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model # 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not find image processor class in the image processor config or the model config. Loading based on pattern matching with the model's feature extractor configuration.\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "pipe = pipeline(\"zero-shot-image-classification\", model=\"patrickjohncyh/fashion-clip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 1.0, 'label': 'short skirt'}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = pipe(\"temp_frame.jpg\", candidate_labels=[\"short skirt\"], multi_class=True) \n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "short_skirt_score = None\n",
    "for prediction in res:\n",
    "    if prediction['label'] == 'short skirt':\n",
    "        short_skirt_score = prediction['score']\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video OK! No Inappropriate Content Detected\n"
     ]
    }
   ],
   "source": [
    "def classify_image(img_array):\n",
    "    predictions = pipe(img_array, candidate_labels=[\"short skirt\", \"short sleeve\", \"long sleeve\", \"short dress\", \"short pants\", \"short sleeve shirt\", \"short sleeve vest\"])\n",
    "    decoded_predictions =  predictions\n",
    "    return decoded_predictions   \n",
    " \n",
    "def classify_video(video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        if not ret:\n",
    "            break\n",
    "   \n",
    "        pil_image = Image.fromarray(np.uint8(frame)) \n",
    "        predicted_class = classify_image(pil_image) \n",
    "\n",
    "        short_skirt_score = None\n",
    "        for prediction in predicted_class:\n",
    "            if prediction['label'] == 'short skirt':\n",
    "                short_skirt_score = prediction['score']\n",
    "                break\n",
    "\n",
    "        if short_skirt_score > 0.7:\n",
    "            print(\"Video Error! The person is wearing a short skirt\")\n",
    "            cap.release()\n",
    "            cv2.destroyAllWindows() \n",
    "            return \n",
    "\n",
    "        cv2.putText(frame, f'Prediction: {short_skirt_score}', (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "        cv2.imshow('Video Classification', frame)\n",
    " \n",
    "        if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "            break\n",
    " \n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows() \n",
    "    print(\"Video OK! No Inappropriate Content Detected\")\n",
    "\n",
    "video_path = 'test.jpg' \n",
    "classify_video(video_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
